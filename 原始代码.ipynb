{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71487df5-0b61-4377-9853-dad48c795547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('1.xlsx')\n",
    "\n",
    "#检查缺失值并删除包含缺失值的行\n",
    "df = df.dropna()\n",
    "\n",
    "#分离特征和标签\n",
    "X= df.drop(columns=['diagnosis'])\n",
    "y= df['diagnosis']\n",
    "\n",
    "#将分类变量转换为独热编码\n",
    "categorical_cols =['1', '2', '3', '4']\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "X = pd.concat([X.drop(columns=categorical_cols), X_encoded], axis=1)\n",
    "\n",
    "# 标准化数值特征\n",
    "val_cols =['5', '6', '7', '8', '9', '10', '11']\n",
    "scaler=StandardScaler()\n",
    "X[val_cols]=scaler.fit_transform(X[val_cols])\n",
    "\n",
    "#将数据转换为 float32 类型\n",
    "X=X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534aa3a6-eff6-4ff1-96c0-da00435d7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集\n",
    "# 分割数据集为训练集和测试集，测试集占30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 定义每个模型的参数网格\n",
    "param_grids = {\n",
    "    'log_reg': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs', 'saga']\n",
    "    },\n",
    "    'rf': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'xgb': {\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [100, 200],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'lgb': {\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'n_estimators': [100, 200],\n",
    "        'boosting_type': ['gbdt', 'dart']\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "        'learning_rate_init': [0.001, 0.01],\n",
    "        'max_iter': [200, 300]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 创建模型实例\n",
    "models = {\n",
    "    'log_reg': LogisticRegression(random_state=42),\n",
    "    'rf': RandomForestClassifier(random_state=42),\n",
    "    'svm': SVC(probability=True, random_state=42),  # 注意：probability=True\n",
    "    'xgb': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'lgb': LGBMClassifier(random_state=42),\n",
    "    'mlp': MLPClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# 存储最佳模型\n",
    "best_models = {}\n",
    "\n",
    "# 遍历每个模型及其对应的参数网格进行网格搜索\n",
    "for model_name in models:\n",
    "    print(f\"Performing grid search for {model_name}...\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=models[model_name],  # 修正拼写\n",
    "        param_grid=param_grids[model_name],  # 修正拼写\n",
    "        scoring='roc_auc',\n",
    "        cv=5,\n",
    "        n_jobs=1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 进行网格搜索并寻找最佳参数\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # 打印最佳参数\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best AUC score: {grid_search.best_score_}\\n\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "#训练集ROC\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算AUC的95%置信区间\n",
    "def compute_ci(y_true, y_pred, n_bootstraps=1000, alpha=0.95):\n",
    "    bootstrapped_scores = []\n",
    "    rng = np.random.RandomState(seed=123)\n",
    "\n",
    "    # 将y_true转换为numpy数组\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        # 生成带放回的随机采样\n",
    "        indices = rng.randint(0, len(y_pred), len(y_pred))\n",
    "\n",
    "        # 确保采样后的y_true至少有两个唯一值，否则跳过\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "\n",
    "        # 计算ROC曲线并得到AUC\n",
    "        score = auc(*roc_curve(y_true[indices], y_pred[indices])[:2])\n",
    "        bootstrapped_scores.append(score)\n",
    "\n",
    "    sorted_scores = np.sort(bootstrapped_scores)\n",
    "    \n",
    "    # 计算下界和上界\n",
    "    lower_bound = np.percentile(sorted_scores, (1 - alpha) / 2 * 100)\n",
    "    upper_bound = np.percentile(sorted_scores, (alpha + (1 - alpha) / 2) * 100)\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# 绘制ROC曲线的函数\n",
    "def plot_roc_curve(model, X, y, label, is_lgb=False):\n",
    "    if is_lgb:\n",
    "        try:\n",
    "            y_pred = model.predict_proba(X, num_iteration=model.best_iteration_)[:, 1]\n",
    "        except AttributeError:\n",
    "            y_pred = model.predict_proba(X)[:, 1]\n",
    "    else:\n",
    "        y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # 计算ROC曲线和AUC\n",
    "    fpr, tpr, _ = roc_curve(y, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # 计算AUC的95%置信区间\n",
    "    ci_lower, ci_upper = compute_ci(y, y_pred)\n",
    "\n",
    "    # 绘制ROC曲线并显示AUC和置信区间，格式调整\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.3f} 95% CI [{ci_lower:.3f}-{ci_upper:.3f}])')\n",
    "\n",
    "# 绘制不同模型的ROC曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# 逻辑回归\n",
    "plot_roc_curve(best_models['log_reg'], X_train, y_train, 'LR')\n",
    "\n",
    "# 随机森林\n",
    "plot_roc_curve(best_models['rf'], X_train, y_train, 'RF')\n",
    "\n",
    "# 多层感知器(MLP)\n",
    "plot_roc_curve(best_models['mlp'], X_train, y_train, 'MLP')\n",
    "\n",
    "# SVM\n",
    "plot_roc_curve(best_models['svm'], X_train, y_train, 'SVM')\n",
    "\n",
    "# XGBoost\n",
    "plot_roc_curve(best_models['xgb'], X_train, y_train, 'XGBoost')\n",
    "\n",
    "# LightGBM\n",
    "plot_roc_curve(best_models['lgb'], X_train, y_train, 'GBM', is_lgb=True)\n",
    "\n",
    "# 添加对角线(随机分类器的参考线)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random classifier (Diagonal)')\n",
    "\n",
    "# 设置图例和标签\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (Training set)')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# 保存图像\n",
    "plt.savefig('roc1.png')\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n",
    "\n",
    "#测试集ROC\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算AUC的95%置信区间\n",
    "def compute_ci(y_true, y_pred, n_bootstraps=1000, alpha=0.95):\n",
    "    bootstrapped_scores = []\n",
    "    rng = np.random.RandomState(seed=123)\n",
    "\n",
    "    # 将y_true转换为numpy数组\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        # 生成带放回的随机采样\n",
    "        indices = rng.randint(0, len(y_pred), len(y_pred))\n",
    "\n",
    "        # 确保采样后的y_true至少有两个唯一值，否则跳过\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "\n",
    "        # 计算ROC曲线并得到AUC\n",
    "        score = auc(*roc_curve(y_true[indices], y_pred[indices])[:2])\n",
    "        bootstrapped_scores.append(score)\n",
    "\n",
    "    sorted_scores = np.sort(bootstrapped_scores)\n",
    "    \n",
    "    # 计算下界和上界\n",
    "    lower_bound = np.percentile(sorted_scores, (1 - alpha) / 2 * 100)\n",
    "    upper_bound = np.percentile(sorted_scores, (alpha + (1 - alpha) / 2) * 100)\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# 绘制ROC曲线的函数\n",
    "def plot_roc_curve(model, X, y, label, is_lgb=False):\n",
    "    if is_lgb:\n",
    "        try:\n",
    "            y_pred = model.predict_proba(X, num_iteration=model.best_iteration_)[:, 1]\n",
    "        except AttributeError:\n",
    "            y_pred = model.predict_proba(X)[:, 1]\n",
    "    else:\n",
    "        y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # 计算ROC曲线和AUC\n",
    "    fpr, tpr, _ = roc_curve(y, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # 计算AUC的95%置信区间\n",
    "    ci_lower, ci_upper = compute_ci(y, y_pred)\n",
    "\n",
    "    # 绘制ROC曲线并显示AUC和置信区间，格式调整\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.3f} 95% CI [{ci_lower:.3f}-{ci_upper:.3f}])')\n",
    "\n",
    "# 绘制不同模型的ROC曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# 逻辑回归\n",
    "plot_roc_curve(best_models['log_reg'], X_test, y_test, 'LR')\n",
    "\n",
    "# 随机森林\n",
    "plot_roc_curve(best_models['rf'], X_test, y_test, 'RF')\n",
    "\n",
    "# 多层感知器(MLP)\n",
    "plot_roc_curve(best_models['mlp'], X_test, y_test, 'MLP')\n",
    "\n",
    "# SVM\n",
    "plot_roc_curve(best_models['svm'], X_test, y_test, 'SVM')\n",
    "\n",
    "# XGBoost\n",
    "plot_roc_curve(best_models['xgb'], X_test, y_test, 'XGBoost')\n",
    "\n",
    "# LightGBM\n",
    "plot_roc_curve(best_models['lgb'], X_test, y_test, 'GBM', is_lgb=True)\n",
    "\n",
    "# 添加对角线(随机分类器的参考线)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random classifier (Diagonal)')\n",
    "\n",
    "# 设置图例和标签\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (Test set)')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# 保存图像\n",
    "plt.savefig('roc2png')\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n",
    "\n",
    "# 加载外部验证集\n",
    "df_external = pd.read_csv('external.csv')\n",
    "\n",
    "# 检查缺失值并删除包含缺失值的行\n",
    "df_external = df_external.dropna()\n",
    "\n",
    "\n",
    "# 对分类变量进行独热编码\n",
    "X_external_encoded = pd.DataFrame(encoder.transform(X_external[categorical_cols]), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "X_external = pd.concat([X_external.drop(columns=categorical_cols), X_external_encoded], axis=1)\n",
    "\n",
    "# 对数值特征进行标准化\n",
    "X_external[val_cols] = scaler.transform(X_external[val_cols])\n",
    "\n",
    "# 确保数据类型一致\n",
    "X_external = X_external.astype(np.float32)\n",
    "\n",
    "# 绘制外部验证集的ROC曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# 使用最佳参数的模型绘制外部验证集的ROC曲线\n",
    "\n",
    "# 逻辑回归\n",
    "plot_roc_curve(best_models['log_reg'], X_external, y_external, 'Logistic Regression')\n",
    "\n",
    "# 随机森林\n",
    "plot_roc_curve(best_models['rf'], X_external, y_external, 'Random Forest')\n",
    "\n",
    "# 多层感知器(MLP)\n",
    "plot_roc_curve(best_models['mlp'], X_external, y_external, 'MLP')\n",
    "\n",
    "# SVM\n",
    "plot_roc_curve(best_models['svm'], X_external, y_external, 'SVM')\n",
    "\n",
    "# XGBoost\n",
    "plot_roc_curve(best_models['xgb'], X_external, y_external, 'XGBoost')\n",
    "\n",
    "# LightGBM\n",
    "plot_roc_curve(best_models['lgb'], X_external, y_external, 'GBM', is_lgb=True)\n",
    "\n",
    "# 添加对角线(随机分类器的参考线)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random classifier (Diagonal)')\n",
    "\n",
    "# 设置图例和标签\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (External Validation Set)')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# 保存图像\n",
    "plt.savefig('roc_curves_external.png')\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n",
    "\n",
    "#训练集校准曲线\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.utils import resample\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def brier_score_confidence_interval(y_true, y_pred_prob, n_bootstraps=1000, alpha=0.05):\n",
    "    brier_scores = []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = resample(np.arange(len(y_true)), n_samples=len(y_true), replace=True)\n",
    "        y_true_sample = np.array(y_true)[indices]\n",
    "        y_pred_prob_sample = np.array(y_pred_prob)[indices]\n",
    "        \n",
    "        brier_score = np.mean((y_pred_prob_sample - y_true_sample) ** 2)\n",
    "        brier_scores.append(brier_score)\n",
    "    \n",
    "    brier_mean = np.mean(brier_scores)\n",
    "    brier_lower = np.percentile(brier_scores, (alpha / 2) * 100)\n",
    "    brier_upper = np.percentile(brier_scores, (1 - alpha / 2) * 100)\n",
    "    \n",
    "    return brier_mean, brier_lower, brier_upper\n",
    "\n",
    "# 绘制校准曲线函数（多模型）\n",
    "def plot_calibration_curves(models, model_names, X, y, dataset_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        y_pred_prob = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        prob_true, prob_pred = calibration_curve(y, y_pred_prob, n_bins=10)\n",
    "        \n",
    "        brier_mean, brier_lower, brier_upper = brier_score_confidence_interval(y, y_pred_prob)\n",
    "        \n",
    "        plt.plot(prob_pred, prob_true, marker='o', linewidth=1, label=f'{name} ({brier_mean:.3f} 95%CI [{brier_lower:.3f}-{brier_upper:.3f}])')\n",
    "\n",
    "    plt.title(f'Calibration Curve ({dataset_name})')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'calibration_curve_{dataset_name.lower()}.png')\n",
    "    plt.show()\n",
    "\n",
    "# 加载训练好的模型\n",
    "xgb_model = best_models['xgb']\n",
    "logistic_model = best_models['log_reg']\n",
    "rf_model = best_models['rf']\n",
    "svm_model = best_models['svm']\n",
    "mlp_model = best_models['mlp']\n",
    "lgb_model = best_models['lgb']\n",
    "\n",
    "# 使用 CalibratedClassifierCV 对所有模型进行校准\n",
    "models = [\n",
    "    CalibratedClassifierCV(xgb_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(logistic_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(rf_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(svm_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(mlp_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(lgb_model, cv=5, method='sigmoid')\n",
    "]\n",
    "\n",
    "# 训练校准后的模型\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# 模型名称\n",
    "model_names = ['XGBoost', 'Logistic Regression', 'Random Forest', 'SVM', 'MLP', 'LightGBM']\n",
    "\n",
    "# 绘制校准曲线并计算 Brier 分数\n",
    "plot_calibration_curves(models, model_names, X_train, y_train, 'Training Set')\n",
    "\n",
    "#测试集校准曲线\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.utils import resample\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def brier_score_confidence_interval(y_true, y_pred_prob, n_bootstraps=1000, alpha=0.05):\n",
    "    brier_scores = []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = resample(np.arange(len(y_true)), n_samples=len(y_true), replace=True)\n",
    "        y_true_sample = np.array(y_true)[indices]\n",
    "        y_pred_prob_sample = np.array(y_pred_prob)[indices]\n",
    "        \n",
    "        brier_score = np.mean((y_pred_prob_sample - y_true_sample) ** 2)\n",
    "        brier_scores.append(brier_score)\n",
    "    \n",
    "    brier_mean = np.mean(brier_scores)\n",
    "    brier_lower = np.percentile(brier_scores, (alpha / 2) * 100)\n",
    "    brier_upper = np.percentile(brier_scores, (1 - alpha / 2) * 100)\n",
    "    \n",
    "    return brier_mean, brier_lower, brier_upper\n",
    "\n",
    "# 绘制校准曲线函数（多模型）\n",
    "def plot_calibration_curves(models, model_names, X, y, dataset_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        y_pred_prob = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        prob_true, prob_pred = calibration_curve(y, y_pred_prob, n_bins=10)\n",
    "        \n",
    "        brier_mean, brier_lower, brier_upper = brier_score_confidence_interval(y, y_pred_prob)\n",
    "        \n",
    "        plt.plot(prob_pred, prob_true, marker='o', linewidth=1, label=f'{name} ({brier_mean:.3f} 95%CI [{brier_lower:.3f}-{brier_upper:.3f}])')\n",
    "\n",
    "    plt.title(f'Calibration Curve ({dataset_name})')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'calibration_curve_17变量男性{dataset_name.lower()}.png')\n",
    "    plt.show()\n",
    "\n",
    "# 加载训练好的模型\n",
    "xgb_model = best_models['xgb']\n",
    "logistic_model = best_models['log_reg']\n",
    "rf_model = best_models['rf']\n",
    "svm_model = best_models['svm']\n",
    "mlp_model = best_models['mlp']\n",
    "lgb_model = best_models['lgb']\n",
    "\n",
    "# 使用 CalibratedClassifierCV 对所有模型进行校准\n",
    "models = [\n",
    "    CalibratedClassifierCV(xgb_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(logistic_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(rf_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(svm_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(mlp_model, cv=5, method='sigmoid'),\n",
    "    CalibratedClassifierCV(lgb_model, cv=5, method='sigmoid')\n",
    "]\n",
    "# 训练校准后的模型\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# 模型名称\n",
    "model_names = ['XGBoost', 'Logistic Regression', 'Random Forest', 'SVM', 'MLP', 'LightGBM']\n",
    "\n",
    "# 绘制校准曲线并计算 Brier 分数\n",
    "plot_calibration_curves(models, model_names, X_test, y_test, 'test Set')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.utils import resample\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# 计算Brier分数的置信区间\n",
    "def brier_score_confidence_interval(y_true, y_pred_prob, n_bootstraps=1000, alpha=0.05):\n",
    "    brier_scores = []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = resample(np.arange(len(y_true)), n_samples=len(y_true), replace=True)\n",
    "        y_true_sample = np.array(y_true)[indices]\n",
    "        y_pred_prob_sample = np.array(y_pred_prob)[indices]\n",
    "        \n",
    "        # 计算Brier分数\n",
    "        brier_score = np.mean((y_pred_prob_sample - y_true_sample) ** 2)\n",
    "        brier_scores.append(brier_score)\n",
    "    \n",
    "    # 计算均值和置信区间\n",
    "    brier_mean = np.mean(brier_scores)\n",
    "    brier_lower = np.percentile(brier_scores, (alpha / 2) * 100)\n",
    "    brier_upper = np.percentile(brier_scores, (1 - alpha / 2) * 100)\n",
    "    \n",
    "    return brier_mean, brier_lower, brier_upper\n",
    "\n",
    "# 绘制校准曲线函数\n",
    "# 绘制校准曲线函数\n",
    "def plot_calibration_curves(models, model_names, X, y, dataset_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        # 预测概率\n",
    "        y_pred_prob = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # 计算校准曲线\n",
    "        prob_true, prob_pred = calibration_curve(y, y_pred_prob, n_bins=10)\n",
    "        \n",
    "        # 计算 Brier 分数和置信区间\n",
    "        brier_mean, brier_lower, brier_upper = brier_score_confidence_interval(y, y_pred_prob)\n",
    "        \n",
    "        # 绘制校准曲线\n",
    "        plt.plot(prob_pred, prob_true, marker='o', linewidth=1, \n",
    "                 label=f'{name} [Brier={brier_mean:.3f} 95%CI ({brier_lower:.3f}-{brier_upper:.3f})]')\n",
    "\n",
    "    plt.title(f'Calibration Curve ({dataset_name})')\n",
    "    plt.xlabel('Mean predicted value')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    \n",
    "    # 将图例固定在右下角\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    # 保存图像\n",
    "    plt.savefig(f'calibration_curve_{dataset_name.lower()}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 训练和校准模型\n",
    "def train_and_calibrate_models(best_models, X_train, y_train):\n",
    "    # 提取模型\n",
    "    xgb_model = best_models['xgb']\n",
    "    logistic_model = best_models['log_reg']\n",
    "    rf_model = best_models['rf']\n",
    "    svm_model = best_models['svm']\n",
    "    mlp_model = best_models['mlp']\n",
    "    lgb_model = best_models['lgb']\n",
    "\n",
    "    # 使用 CalibratedClassifierCV 对模型进行校准\n",
    "    models = [\n",
    "        CalibratedClassifierCV(xgb_model, cv=5, method='sigmoid'),\n",
    "        CalibratedClassifierCV(logistic_model, cv=5, method='sigmoid'),\n",
    "        CalibratedClassifierCV(rf_model, cv=5, method='sigmoid'),\n",
    "        CalibratedClassifierCV(svm_model, cv=5, method='sigmoid'),\n",
    "        CalibratedClassifierCV(mlp_model, cv=5, method='sigmoid'),\n",
    "        CalibratedClassifierCV(lgb_model, cv=5, method='sigmoid')\n",
    "    ]\n",
    "    \n",
    "    # 训练校准后的模型\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    return models\n",
    "\n",
    "# 模型名称\n",
    "model_names = ['XGBoost', 'LR', 'RF', 'SVM', 'MLP', 'GBM']\n",
    "\n",
    "# 训练校准后的模型\n",
    "models = train_and_calibrate_models(best_models, X_train, y_train)\n",
    "\n",
    "# 绘制校准曲线并计算 Brier 分数，使用外部验证集 (external validation set)\n",
    "plot_calibration_curves(models, model_names, X_external, y_external, 'Validation Set')\n",
    "\n",
    "#训练集DCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 函数：计算模型的净效益\n",
    "def calculate_net_benefit_model(thresh_group, y_pred_score, y_label):\n",
    "    net_benefit_model = np.zeros_like(thresh_group)\n",
    "    n = len(y_label)\n",
    "    for i, thresh in enumerate(thresh_group):\n",
    "        y_pred_label = y_pred_score > thresh\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, y_pred_label).ravel()\n",
    "        net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_model[i] = net_benefit\n",
    "    return net_benefit_model\n",
    "\n",
    "# 函数：计算Treat All策略的净效益\n",
    "def calculate_net_benefit_all(thresh_group, y_label):\n",
    "    net_benefit_all = np.zeros_like(thresh_group)\n",
    "    n = len(y_label)\n",
    "    for i, thresh in enumerate(thresh_group):\n",
    "        predictions = np.ones(n)  # 假设全体都被预测为阳性\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, predictions).ravel()\n",
    "        net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_all[i] = net_benefit\n",
    "    return net_benefit_all\n",
    "\n",
    "# 函数：绘制DCA曲线\n",
    "def plot_DCA(ax, thresh_group, net_benefit_model, label, color):\n",
    "    ax.plot(thresh_group, net_benefit_model, label=label, color=color, linewidth=2)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(net_benefit_model.min() - 0.05, net_benefit_model.max() + 0.05)\n",
    "    ax.set_xlabel('Threshold Probability', fontsize=12, fontweight='bold', fontfamily='Arial')\n",
    "    ax.set_ylabel('Net Benefit', fontsize=12, fontweight='bold', fontfamily='Arial')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.legend(loc='upper right', fontsize=10, frameon=False)\n",
    "    return ax\n",
    "\n",
    "# 主绘图代码\n",
    "def plot_decision_curve_analysis(models, model_names, thresh_group, X_train, y_train, fig_name='dca_plot.png'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # 计算Treat All策略的净效益\n",
    "    net_benefit_all = calculate_net_benefit_all(thresh_group, y_train)\n",
    "\n",
    "    # Treat all和Treat none的基线策略\n",
    "    ax.plot(thresh_group, net_benefit_all, color='black', linestyle='-', label='Treat all', linewidth=2)\n",
    "    ax.plot((0, 1), (0, 0), color='gray', linestyle='--', label='Treat none', linewidth=2)\n",
    "\n",
    "    # 计算并绘制每个模型的净效益曲线\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    for i, (label, model) in enumerate(models.items()):\n",
    "        # 获取每个模型的预测概率\n",
    "        preds = model.predict_proba(X_train)[:, 1]  # 使用模型的训练集预测概率\n",
    "        net_benefit_model = calculate_net_benefit_model(thresh_group, preds, y_train)\n",
    "        # 使用model_names中的对应名称作为图例\n",
    "        ax = plot_DCA(ax, thresh_group, net_benefit_model, model_names[i], colors[i])\n",
    "\n",
    "    # 图像的美观设置\n",
    "    ax.set_title('Decision Curve Analysis (Training set)', fontsize=16, fontweight='bold', fontfamily='Arial', pad=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    # 保存图像\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 测试数据\n",
    "thresh_group = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# 模型名称\n",
    "model_names = ['LR', 'RF', 'SVM', 'XGBoost', 'GBM', 'MLP']\n",
    "\n",
    "# 调用绘制函数，使用最佳模型\n",
    "plot_decision_curve_analysis(best_models, model_names, thresh_group, X_train, y_train, fig_name='dca_1.png')\n",
    "\n",
    "#测试集DCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 函数：计算模型的净效益\n",
    "def calculate_net_benefit_model(thresh_group, y_pred_score, y_label):\n",
    "    net_benefit_model = np.zeros_like(thresh_group)\n",
    "    n = len(y_label)\n",
    "    for i, thresh in enumerate(thresh_group):\n",
    "        y_pred_label = y_pred_score > thresh\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, y_pred_label).ravel()\n",
    "        net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_model[i] = net_benefit\n",
    "    return net_benefit_model\n",
    "\n",
    "# 函数：计算Treat All策略的净效益\n",
    "def calculate_net_benefit_all(thresh_group, y_label):\n",
    "    net_benefit_all = np.zeros_like(thresh_group)\n",
    "    n = len(y_label)\n",
    "    for i, thresh in enumerate(thresh_group):\n",
    "        predictions = np.ones(n)  # 假设全体都被预测为阳性\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, predictions).ravel()\n",
    "        net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_all[i] = net_benefit\n",
    "    return net_benefit_all\n",
    "\n",
    "# 函数：绘制DCA曲线\n",
    "def plot_DCA(ax, thresh_group, net_benefit_model, label, color):\n",
    "    ax.plot(thresh_group, net_benefit_model, label=label, color=color, linewidth=2)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(net_benefit_model.min() - 0.05, net_benefit_model.max() + 0.05)\n",
    "    ax.set_xlabel('Threshold Probability', fontsize=12, fontweight='bold', fontfamily='Arial')\n",
    "    ax.set_ylabel('Net Benefit', fontsize=12, fontweight='bold', fontfamily='Arial')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.legend(loc='upper right', fontsize=10, frameon=False)\n",
    "    return ax\n",
    "\n",
    "# 主绘图代码\n",
    "def plot_decision_curve_analysis(models, model_names, thresh_group, X_test, y_test, fig_name='dca_plot.png'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # 计算Treat All策略的净效益\n",
    "    net_benefit_all = calculate_net_benefit_all(thresh_group, y_test)\n",
    "\n",
    "    # Treat all和Treat none的基线策略\n",
    "    ax.plot(thresh_group, net_benefit_all, color='black', linestyle='-', label='Treat all', linewidth=2)\n",
    "    ax.plot((0, 1), (0, 0), color='gray', linestyle='--', label='Treat none', linewidth=2)\n",
    "\n",
    "    # 计算并绘制每个模型的净效益曲线\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    for i, (label, model) in enumerate(models.items()):\n",
    "        # 获取每个模型的预测概率\n",
    "        preds = model.predict_proba(X_test)[:, 1]  # 使用模型的预测概率\n",
    "        net_benefit_model = calculate_net_benefit_model(thresh_group, preds, y_test)\n",
    "        # 使用model_names中的对应名称作为图例\n",
    "        ax = plot_DCA(ax, thresh_group, net_benefit_model, model_names[i], colors[i])\n",
    "\n",
    "    # 图像的美观设置\n",
    "    ax.set_title('Decision Curve Analysis (Test set)', fontsize=16, fontweight='bold', fontfamily='Arial', pad=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    # 保存图像\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 测试数据\n",
    "thresh_group = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# 模型名称\n",
    "model_names = ['LR', 'RF', 'SVM', 'XGBoost', 'GBM', 'MLP']\n",
    "\n",
    "# 调用绘制函数，使用最佳模型\n",
    "plot_decision_curve_analysis(best_models, model_names, thresh_group, X_test, y_test, fig_name='dca_2.png')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 函数：计算模型的净效益\n",
    "def calculate_net_benefit_model(thresh_group, y_pred_score, y_label):\n",
    "    net_benefit_model = np.zeros_like(thresh_group)\n",
    "    n = len(y_label)\n",
    "    for i, thresh in enumerate(thresh_group):\n",
    "        y_pred_label = y_pred_score > thresh\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, y_pred_label).ravel()\n",
    "        net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_model[i] = net_benefit\n",
    "    return net_benefit_model\n",
    "\n",
    "# 函数：计算Treat All策略的净效益\n",
    "def calculate_net_benefit_all(thresh_group, y_label):\n",
    "    net_benefit_all = np.zeros_like(thresh_group)\n",
    "    n = len(y_label)\n",
    "    for i, thresh in enumerate(thresh_group):\n",
    "        predictions = np.ones(n)  # 假设全体都被预测为阳性\n",
    "        tn, fp, fn, tp = confusion_matrix(y_label, predictions).ravel()\n",
    "        net_benefit = (tp / n) - (fp / n) * (thresh / (1 - thresh))\n",
    "        net_benefit_all[i] = net_benefit\n",
    "    return net_benefit_all\n",
    "\n",
    "# 函数：绘制DCA曲线\n",
    "def plot_DCA(ax, thresh_group, net_benefit_model, label, color):\n",
    "    ax.plot(thresh_group, net_benefit_model, label=label, color=color, linewidth=2)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(net_benefit_model.min() - 0.05, net_benefit_model.max() + 0.05)\n",
    "    ax.set_xlabel('Threshold Probability', fontsize=12, fontweight='bold', fontfamily='Arial')\n",
    "    ax.set_ylabel('Net Benefit', fontsize=12, fontweight='bold', fontfamily='Arial')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.legend(loc='upper right', fontsize=10, frameon=False)\n",
    "    return ax\n",
    "\n",
    "# 主绘图代码\n",
    "def plot_decision_curve_analysis(models, model_names, thresh_group, X_external, y_external, fig_name='dca_plot.png'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # 计算Treat All策略的净效益\n",
    "    net_benefit_all = calculate_net_benefit_all(thresh_group, y_external)\n",
    "\n",
    "    # Treat all和Treat none的基线策略\n",
    "    ax.plot(thresh_group, net_benefit_all, color='black', linestyle='-', label='Treat all', linewidth=2)\n",
    "    ax.plot((0, 1), (0, 0), color='gray', linestyle='--', label='Treat none', linewidth=2)\n",
    "\n",
    "    # 计算并绘制每个模型的净效益曲线\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    for i, (label, model) in enumerate(models.items()):\n",
    "        # 获取每个模型在外部验证集上的预测概率\n",
    "        preds = model.predict_proba(X_external)[:, 1]  # 使用模型的预测概率\n",
    "        net_benefit_model = calculate_net_benefit_model(thresh_group, preds, y_external)\n",
    "        # 使用model_names中的对应名称作为图例\n",
    "        ax = plot_DCA(ax, thresh_group, net_benefit_model, model_names[i], colors[i])\n",
    "\n",
    "    # 图像的美观设置\n",
    "    ax.set_title('Decision Curve Analysis (Validation Set)', fontsize=16, fontweight='bold', fontfamily='Arial', pad=20)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    # 保存图像\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 使用外部验证集进行DCA分析\n",
    "thresh_group = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# 模型名称\n",
    "model_names = ['LR', 'RF','SVM','XGBoost',   'GBM' ,'MLP']\n",
    "\n",
    "# 调用绘制函数，使用最佳模型\n",
    "plot_decision_curve_analysis(best_models, model_names, thresh_group, X_external, y_external, fig_name='dca_3.png')\n",
    "\n",
    "#测试集PR曲线\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def plot_pr_curve(ax, y_true, y_scores, label, color, n_bootstraps=1000, alpha=0.95):\n",
    "    \"\"\"绘制PR曲线并计算AUC及95%置信区间\"\"\"\n",
    "    # 将y_true和y_scores转换为NumPy数组，避免pandas的索引问题\n",
    "    y_true = np.array(y_true)\n",
    "    y_scores = np.array(y_scores)\n",
    "    \n",
    "    # 计算 PR 曲线\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    auc_score = auc(recall, precision)\n",
    "\n",
    "    # Bootstrap 计算 95% 置信区间\n",
    "    bootstrapped_scores = []\n",
    "    rng = np.random.RandomState(seed=42)  # 设置随机种子确保可复现性\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = resample(np.arange(len(y_scores)), random_state=rng)\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        precision_boot, recall_boot, _ = precision_recall_curve(y_true[indices], y_scores[indices])\n",
    "        auc_boot = auc(recall_boot, precision_boot)\n",
    "        bootstrapped_scores.append(auc_boot)\n",
    "    \n",
    "    # 计算置信区间\n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    lower_bound = np.percentile(sorted_scores, ((1 - alpha) / 2) * 100)\n",
    "    upper_bound = np.percentile(sorted_scores, (alpha + (1 - alpha) / 2) * 100)\n",
    "    \n",
    "    # 绘制 PR 曲线并在图例中显示 AUC 和 95% 置信区间\n",
    "    ax.plot(recall, precision, \n",
    "            label=f'{label} (AUC = {auc_score:.3f} 95% CI [{lower_bound:.3f}-{upper_bound:.3f}])', \n",
    "            color=color, linewidth=2)\n",
    "    \n",
    "    # 设置图表样式\n",
    "    ax.set_xlabel(\"Recall\", fontdict={'family': 'Times New Roman', 'fontsize': 15})\n",
    "    ax.set_ylabel(\"Precision\", fontdict={'family': 'Times New Roman', 'fontsize': 15})\n",
    "\n",
    "    ax.legend(loc='lower left', fontsize=12)\n",
    "    return ax\n",
    "\n",
    "\n",
    "# 绘制测试集的PR曲线\n",
    "fig_test, ax_test = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# 自定义颜色列表\n",
    "colors = plt.get_cmap(\"tab10\").colors\n",
    "\n",
    "# 使用最佳模型进行预测并绘制PR曲线\n",
    "# SVM模型\n",
    "svm_preds_test = best_models['svm'].predict_proba(X_test)[:, 1]\n",
    "ax_test = plot_pr_curve(ax_test, y_test, svm_preds_test, 'SVM', colors[0])\n",
    "\n",
    "# XGBoost模型\n",
    "xgb_preds_test = best_models['xgb'].predict_proba(X_test)[:, 1]\n",
    "ax_test = plot_pr_curve(ax_test, y_test, xgb_preds_test, 'XGBoost', colors[1])\n",
    "\n",
    "# GBM模型\n",
    "gbm_preds_test = best_models['lgb'].predict_proba(X_test)[:, 1]\n",
    "ax_test = plot_pr_curve(ax_test, y_test, gbm_preds_test, 'GBM', colors[2])\n",
    "\n",
    "# 逻辑回归模型\n",
    "log_reg_preds_test = best_models['log_reg'].predict_proba(X_test)[:, 1]\n",
    "ax_test = plot_pr_curve(ax_test, y_test, log_reg_preds_test, 'LR', colors[3])\n",
    "\n",
    "# 随机森林模型\n",
    "rf_preds_test = best_models['rf'].predict_proba(X_test)[:, 1]\n",
    "ax_test = plot_pr_curve(ax_test, y_test, rf_preds_test, 'RF', colors[4])\n",
    "\n",
    "# MLP模型\n",
    "mlp_preds_test = best_models['mlp'].predict_proba(X_test)[:, 1]\n",
    "ax_test = plot_pr_curve(ax_test, y_test, mlp_preds_test, 'MLP', colors[5])\n",
    "\n",
    "# 设置图标题和显示\n",
    "plt.title('Precision-Recall Curves (Test set)', fontdict={'family': 'Times New Roman', 'fontsize': 18, 'fontweight': 'bold'})\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pr_curves_1.png\")\n",
    "plt.show()\n",
    "\n",
    "#各模型训练集及测试集的预测指标\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "# 计算指标函数\n",
    "def calculate_metrics(y_true, y_pred, y_scores):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensitivity = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # 防止分母为零\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_scores)  # 计算AUC\n",
    "    return accuracy, sensitivity, precision, specificity, f1, auc\n",
    "\n",
    "# 打印模型评估指标函数\n",
    "def print_model_metrics(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_train_scores = model.predict_proba(X_train)[:, 1]  # 用 predict_proba 得到分数\n",
    "        y_test_scores = model.predict_proba(X_test)[:, 1]\n",
    "        y_train_pred = (y_train_scores > 0.5).astype(int)\n",
    "        y_test_pred = (y_test_scores > 0.5).astype(int)\n",
    "    else:\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_train_scores = y_train_pred  # 对于不提供概率的模型，使用预测值作为近似分数\n",
    "        y_test_scores = y_test_pred\n",
    "\n",
    "    # 计算训练集和测试集的评估指标\n",
    "    accuracy_train, sensitivity_train, precision_train, specificity_train, f1_train, auc_train = calculate_metrics(y_train, y_train_pred, y_train_scores)\n",
    "    accuracy_test, sensitivity_test, precision_test, specificity_test, f1_test, auc_test = calculate_metrics(y_test, y_test_pred, y_test_scores)\n",
    "\n",
    "    # 输出训练集和测试集的结果\n",
    "    print(f\"--- {model_name} ---\")\n",
    "    print(f\"Training Set Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy_train:.4f}, Sensitivity: {sensitivity_train:.4f}, Precision: {precision_train:.4f}, Specificity: {specificity_train:.4f}, F1 Score: {f1_train:.4f}, AUC: {auc_train:.4f}\")\n",
    "    \n",
    "    print(f\"Test Set Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy_test:.4f}, Sensitivity: {sensitivity_test:.4f}, Precision: {precision_test:.4f}, Specificity: {specificity_test:.4f}, F1 Score: {f1_test:.4f}, AUC: {auc_test:.4f}\")\n",
    "    print()\n",
    "\n",
    "# 使用之前找到的最佳模型\n",
    "models = {\n",
    "    'SVM': best_models['svm'],\n",
    "    'XGBoost': best_models['xgb'],\n",
    "    'LightGBM': best_models['lgb'],\n",
    "    'Logistic Regression': best_models['log_reg'],\n",
    "    'Random Forest': best_models['rf'],\n",
    "    'MLP': best_models['mlp']\n",
    "}\n",
    "\n",
    "# 假设你已经有 X_train, y_train, X_test, y_test 数据集\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)  # 确保每个模型都被训练\n",
    "    print_model_metrics(model, X_train, y_train, X_test, y_test, model_name)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_excel('1.xlsx')\n",
    "\n",
    "# 筛选特征\n",
    "selected_features = ['adlab_c', 'systo', 'diasto', 'bmi', 'bl_crea', 'bl_cho', 'bl_tg', 'bl_hdl', 'bl_ldl', 'bl_ua', 'bl_hct', 'bl_hgb', 'bl_cysc', 'age', 'iadl', 'tyg', 'grip']\n",
    "\n",
    "X = data[selected_features]\n",
    "y = data['diagnosis']\n",
    "\n",
    "# 分割数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "# 创建并训练XGBoost模型，使用指定参数\n",
    "xgb_model = xgb.XGBClassifier(learning_rate: 0.1, max_depth: 3, n_estimators: 100, subsample: 0.8)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 使用TreeExplainer来计算SHAP值\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 创建SHAP蜂群图（dot plot）\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"dot\")\n",
    "\n",
    "# 创建变量重要性排序图（bar plot）\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "\n",
    "# 创建SHAP散点图（以'ADL score'为例）\n",
    "shap.dependence_plot(\"age\", shap_values, X_test)\n",
    "\n",
    "# 选择第 1 类的 SHAP 值\n",
    "shap_values_class_1 = shap_values[:, 0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
